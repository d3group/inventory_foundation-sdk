{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database management\n",
    "\n",
    "> Classes and functions for managing access to the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp db_mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/11/25 13:46:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using                                                                  <a href=\"file:///Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-packages/kedro/framework/project/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-packages/kedro/framework/project/__init__.py#270\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-p</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ackages/kedro/framework/project/rich_logging.yml'</span> as logging           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         configuration.                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/11/25 13:46:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using                                                                  \u001b]8;id=850623;file:///Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-packages/kedro/framework/project/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=932813;file:///Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-packages/kedro/framework/project/__init__.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'/Users/moritzbeckmail.de/miniconda3/envs/if_sdk/lib/python3.11/site-p\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mackages/kedro/framework/project/rich_logging.yml'\u001b[0m as logging           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         configuration.                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psycopg2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_db_credentials():\n",
    "    \n",
    "    \"\"\"\n",
    "    Fetch PostgreSQL database credentials from the configuration file of the kedro project.\n",
    "\n",
    "    Uses `OmegaConfigLoader` to load credentials stored under `credentials.postgres`.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the database connection details (e.g., host, port, user, password, dbname).\n",
    "    \"\"\"\n",
    "\n",
    "    conf_path = str(Path(settings.CONF_SOURCE))\n",
    "    conf_loader = OmegaConfigLoader(conf_source=conf_path)\n",
    "    db_credentials = conf_loader[\"credentials\"][\"postgres\"]\n",
    "\n",
    "    return db_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def insert_multi_rows(\n",
    "    data_to_insert: pd.DataFrame,\n",
    "    table_name: str,\n",
    "    column_names: list,\n",
    "    types: list,\n",
    "    cur,\n",
    "    conn,\n",
    "    return_with_ids: bool = False,\n",
    "    unique_columns: list = None,  # mandatory if return_with_ids is True\n",
    ") -> pd.DataFrame | None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Inserts data into the specified database table, with an optional return of database-assigned IDs.\n",
    "\n",
    "    Args:\n",
    "        data_to_insert (pd.DataFrame): DataFrame containing the data to be inserted.\n",
    "        table_name (str): Name of the target database table.\n",
    "        column_names (list): List of column names for the target table.\n",
    "        types (list): List of Python types (e.g., [int, float]) for data conversion.\n",
    "        cur (psycopg2.cursor): Database cursor for executing SQL commands.\n",
    "        conn (psycopg2.connection): Database connection for committing transactions.\n",
    "        return_with_ids (bool): If True, returns the original DataFrame with an additional \"ID\" column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: Original DataFrame with an \"ID\" column if `return_with_ids` is True; otherwise, None.\n",
    "    \"\"\"\n",
    "    logger.info(\"-- in insert multi rows -- checking data\")\n",
    "\n",
    "    # Check for NaN values and log a warning if any are found\n",
    "    if data_to_insert.isnull().values.any():\n",
    "        logger.warning(\"There are NaNs in the data\")\n",
    "    \n",
    "    # Ensure the DataFrame has the correct number of columns\n",
    "    if len(column_names) != data_to_insert.shape[1]:\n",
    "        raise ValueError(\"Number of column names does not match the number of columns in the DataFrame.\")\n",
    "    if len(types) != data_to_insert.shape[1]:\n",
    "        raise ValueError(\"Number of types does not match the number of columns in the DataFrame.\")\n",
    "    \n",
    "    logger.info(\"-- in insert multi rows -- converting data to list of tuples\")\n",
    "    # Convert to list of tuples and apply type casting\n",
    "\n",
    "    data_values = data_to_insert.values.tolist()\n",
    "    data_values = [tuple(typ(val) for typ, val in zip(types, row)) for row in data_values]\n",
    "    \n",
    "    logger.info(\"-- in insert multi rows -- preparing SQL\")\n",
    "    # Create SQL placeholders and query\n",
    "    placeholders = \", \".join([\"%s\"] * len(column_names))\n",
    "    column_names_str = \", \".join(f'\"{col}\"' for col in column_names)\n",
    "    \n",
    "\n",
    "    batch_size_for_commit = 1_000_000  # Adjust this based on your dataset size and transaction tolerance\n",
    "    row_count = 0\n",
    "\n",
    "    if return_with_ids:\n",
    "        if not unique_columns:\n",
    "            raise ValueError(\"unique_columns must be provided when return_with_ids is True\")\n",
    "\n",
    "        unique_columns_str = \", \".join(f'\"{col}\"' for col in unique_columns)\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} ({column_names_str})\n",
    "            VALUES ({placeholders})\n",
    "            ON CONFLICT ({unique_columns_str})\n",
    "            DO UPDATE SET \"{unique_columns[0]}\" = EXCLUDED.\"{unique_columns[0]}\"\n",
    "            RETURNING \"ID\";\n",
    "        \"\"\"\n",
    "        ids = []\n",
    "\n",
    "        \n",
    "        \n",
    "        # Insert row by row and collect IDs\n",
    "        with tqdm(total=len(data_values), desc=\"Inserting rows\") as pbar:\n",
    "            for row in data_values:\n",
    "                cur.execute(insert_query, row)\n",
    "                row_id = cur.fetchone()\n",
    "                if row_id:\n",
    "                    ids.append(row_id[0])\n",
    "                row_count += 1\n",
    "                pbar.update(1)  # Update progress bar for each row\n",
    "                \n",
    "                # Commit every batch_size_for_commit rows\n",
    "                if row_count % batch_size_for_commit == 0:\n",
    "                    conn.commit()  # Commit the transaction\n",
    "        conn.commit() \n",
    "        \n",
    "        # Add IDs back to the original DataFrame\n",
    "        data_with_ids = data_to_insert.copy()\n",
    "        data_with_ids[\"ID\"] = ids\n",
    "        return data_with_ids\n",
    "\n",
    "    else:\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} ({column_names_str})\n",
    "            VALUES ({placeholders})\n",
    "            ON CONFLICT DO NOTHING;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert row by row without returning IDs\n",
    "        with tqdm(total=len(data_values), desc=\"Inserting rows\") as pbar:\n",
    "            for row in data_values:\n",
    "                cur.execute(insert_query, row)\n",
    "                row_count += 1\n",
    "                pbar.update(1)  # Update progress bar for each row\n",
    "                if row_count % batch_size_for_commit == 0:\n",
    "                    conn.commit()  # Commit the transaction\n",
    "                \n",
    "        conn.commit()  # Commit all changes after processing\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "\n",
    "class SQLDatabase:\n",
    "    def __init__(self, autocommit=True):\n",
    "        self._credentials = get_db_credentials()[\"con\"]\n",
    "        self.connection = None\n",
    "        self.autocommit = autocommit\n",
    "\n",
    "    def connect(self):\n",
    "        if not self.connection:\n",
    "            self.connection = psycopg2.connect(self._credentials)\n",
    "            self.connection.autocommit = self.autocommit\n",
    "\n",
    "    def close(self):\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.connect()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if exc_type:\n",
    "            self.connection.rollback()\n",
    "        elif not self.autocommit:\n",
    "            self.connection.commit()\n",
    "        self.close()\n",
    "\n",
    "    def execute_query(self, query: str, params: tuple = None, fetchall: bool = False, fetchone: bool = False, commit: bool = False):\n",
    "        if fetchall and fetchone:\n",
    "            raise ValueError(\"Both fetchall and fetchone cannot be True\")\n",
    "        if not self.connection:\n",
    "            self.connect()\n",
    "        with self.connection.cursor() as cur:\n",
    "            cur.execute(query, params)\n",
    "            result = cur.fetchall() if fetchall else cur.fetchone() if fetchone else None\n",
    "        if commit and self.autocommit:\n",
    "            self.connection.commit()\n",
    "        return result\n",
    "\n",
    "    def execute_multiple_queries(self, queries: list | str, params: list = None, fetchrows: bool = False, commit: bool = False):\n",
    "        if not self.connection:\n",
    "            self.connect()\n",
    "        results = []\n",
    "        with self.connection.cursor() as cur:\n",
    "            if fetchrows:\n",
    "                if isinstance(queries, str):\n",
    "                    queries = [queries] * len(params)\n",
    "                for query, par in zip(queries, params):\n",
    "                    cur.execute(query, par)\n",
    "                    results.append(cur.fetchone())\n",
    "            else:\n",
    "                if not isinstance(queries, str):\n",
    "                    raise ValueError(\"For batch execution use a single query with multiple params (set fetchrows=True otherwise)\")\n",
    "                cur.executemany(queries, params)\n",
    "        if commit and self.autocommit:\n",
    "            self.connection.commit()\n",
    "        return results if fetchrows else None\n",
    "\n",
    "    def fetch_ids_bulk(self, table_name: str, id_column: str, column_names: list, rows: list[tuple]) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve IDs in one bulk query using the VALUES construct.\n",
    "        \"\"\"\n",
    "        if not rows:\n",
    "            return []\n",
    "        # Build derived table with column names matching those in the main table.\n",
    "        columns_str = \", \".join(column_names)\n",
    "        join_clause = \" AND \".join([f\"t.{col} = v.{col}\" for col in column_names])\n",
    "        query = f\"\"\"\n",
    "            SELECT t.{id_column}\n",
    "            FROM {table_name} t\n",
    "            JOIN (\n",
    "                VALUES %s\n",
    "            ) AS v({columns_str})\n",
    "            ON {join_clause}\n",
    "        \"\"\"\n",
    "        if not self.connection:\n",
    "            self.connect()\n",
    "        with self.connection.cursor() as cur:\n",
    "            execute_values(cur, query, rows, page_size=100)\n",
    "            results = cur.fetchall()\n",
    "        return [int(r[0]) for r in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "if_sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
